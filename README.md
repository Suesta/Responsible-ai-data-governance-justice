# Responsible AI & Data Governance in Justice Systems

Case study from an MSc in Data Science on how to design **data governance** and **AI governance** for high-risk justice systems.  
The project focuses on **recidivism risk scoring** with AI agents, under strict **GDPR** and **EU AI Act** constraints, and explores how a data scientist should integrate:

- Data governance and security
- Privacy by design & by default
- Fairness and non-discrimination
- Transparency, explainability and accountability

Although this repository does not include source code, it is highly relevant to **practical Data Science in regulated environments**, especially for roles dealing with **responsible AI, ML in production and high-risk decision systems**.

---

## Context

This work was developed as part of the MSc in Data Science (course *Fundamentos de Ciencia de Datos*).  
The assignment simulates a startup that wants to launch a product for **recidivism risk prediction** using AI agents in the justice domain.

The report analyses:

- How a data-driven organisation should **govern data and AI** in this context  
- Which **ethical and legal requirements** (GDPR, EU AI Act, AI governance frameworks) must be translated into technical and organisational controls  
- How a Data Scientist should **balance model performance with fairness, privacy and explainability**

---

## What this project covers (from a Data Science perspective)

Even without code, the project exercises core responsibilities of a Data Scientist working with sensitive data:

- **Data governance design**
  - Roles and responsibilities around data
  - Data lifecycle: collection, quality, access, retention and deletion
  - Security controls (confidentiality, integrity, availability)

- **AI governance for high-risk systems**
  - Integration of GDPR and EU AI Act into the ML workflow  
  - Human-in-the-loop decision making  
  - Documentation, auditability and traceability of models

- **Ethics & responsible ML**
  - Fairness and bias analysis in risk scoring systems  
  - Trade-offs between accuracy, interpretability and equity  
  - Design of decision points and ethical checkpoints across the ML lifecycle

- **Regulatory-aware DS practice**
  - Translating legal and policy requirements into concrete technical constraints  
  - Justifying modelling choices to non-technical stakeholders (regulators, legal teams, public sector)

---

## Repository structure

```text
.
├── ENUNCIADO + CRITERIOS.pdf   # Original assignment brief and evaluation criteria (Spanish)
├── LICENSE                     # MIT license for this repository
├── README.md                   # Project description (this file)
└── Victor_Suesta_PEC2.pdf      # Final report with full analysis (Spanish)
````

* **Victor_Suesta_PEC2.pdf**
  Main deliverable: detailed written analysis of data governance, AI governance and ethical design for recidivism risk scoring.

* **ENUNCIADO + CRITERIOS.pdf**
  Assignment statement and grading rubric, providing context on objectives and constraints.

---

## How this relates to Data Science roles

This case study is especially relevant for positions such as:

* Data Scientist / ML Engineer working with **regulated data** (finance, health, justice, public sector)
* Roles focused on **Responsible AI**, **model risk management** or **AI governance**
* Data professionals who need to justify ML solutions to **regulators, legal teams or compliance**

Key takeaways:

* Being a strong Data Scientist is not only about modelling; it also requires understanding **governance, regulation and ethics**.
* High-impact ML systems must be designed from the start with **privacy, security, fairness and explainability** as first-class requirements.

---

